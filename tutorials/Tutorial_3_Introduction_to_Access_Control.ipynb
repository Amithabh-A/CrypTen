{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Introduction to Access Control\n",
    "\n",
    "We can now start using CrypTen to carry out private computations in some common use cases. In this tutorial, we will demonstrate how CrypTen would apply for the scenarios described in the Introduction. In all scenarios, we'll use a simple two-party setting and demonstrate how we can learn a linear SVM. In the process, we will see how access control works in CrypTen.\n",
    "\n",
    "As usual, we'll begin by importing the `crypten` and `torch` libraries, and initialize `crypten` with `crypten.init()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "In this tutorial, we will train a Linear SVM to perform binary classification. We will first generate 1000 ground truth samples using 100 features and a randomly generated hyperplane to separate positive and negative examples. \n",
    "\n",
    "(Note: this will cause our classes to be linearly separable, so a linear SVM will be able to classify with perfect accuracy given the right parameters.)\n",
    "\n",
    "We will also include a test set of examples (that are also linearly separable by the same hyperplane) to show that the model learns a general hyperplane rather than memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "num_train_examples = 1000\n",
    "num_test_examples = 100\n",
    "epochs = 40\n",
    "lr = 3.0\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(1)\n",
    "\n",
    "features = torch.randn(num_features, num_train_examples)\n",
    "w_true = torch.randn(1, num_features)\n",
    "b_true = torch.randn(1)\n",
    "\n",
    "labels = w_true.matmul(features).add(b_true).sign()\n",
    "\n",
    "test_features = torch.randn(num_features, num_test_examples)\n",
    "test_labels = w_true.matmul(test_features).add(b_true).sign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated our dataset, we will train our SVM in four different access control scenarios across two parties, Alice and Bob:\n",
    "\n",
    "- Data Labeling: Alice has access to features, while Bob has access to labels\n",
    "- Feature Aggregation: Alice has access to the first 50 features, while Bob has access to the last 50 features\n",
    "- Data Augmentation: Alice has access to the first 500 examples, while Bob has access to the last 500 examples\n",
    "- Model Hiding: Alice has access to `w_true` and `b_true`, while Bob has access to data samples to be classified\n",
    "\n",
    "Throughout this tutorial, we will assume Alice is using the rank 0 process, while Bob is using the rank 1 process. Additionally we will initialize our weights using random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALICE = 0\n",
    "BOB = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction.ipynb\n",
      "Tutorial_1_Basics_of_CrypTen_Tensors.ipynb\n",
      "Tutorial_2_Inside_CrypTensors.ipynb\n",
      "Tutorial_3_Introduction_to_Access_Control.ipynb\n",
      "Tutorial_4_Classification_with_Encrypted_Neural_Networks.ipynb\n",
      "Tutorial_5_Under_the_hood_of_Encrypted_Networks.ipynb\n",
      "Tutorial_6_CrypTen_on_AWS_instances.ipynb\n",
      "Tutorial_7_Training_an_Encrypted_Neural_Network.ipynb\n",
      "__init__.py\n",
      "crypten_utils.py\n",
      "\u001b[34mexamples\u001b[m\u001b[m\n",
      "mnist_utils.py\n",
      "\u001b[34mmodels\u001b[m\u001b[m\n",
      "test.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "os.path.dirname(os.path.dirname(os.path.abspath(__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = \"/Users/amithabh_a/dev/garbage/CrypTen/tutorials\"\n",
    "parent_dir  = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each example, we will use the same code to train our linear SVM once the features and labels are properly encrypted. This code is contained in `examples/mpc_linear_svm`, but it is unnecessary to understand the training code to properly use access control. The training process itself is discussed in depth in later tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpc_linear_svm.mpc_linear_svm import train_linear_svm, evaluate_linear_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving / Loading Data\n",
    "\n",
    "We have now generated features and labels for our model to learn. In the scenarios we explore in this tutorial, we would like to ensure that each party only has access to some subset of the data we have generated. To do so, we will use special save / load methods that CrypTen provides to handle loading only to a specified party and synchronizing across processes. \n",
    "\n",
    "We will use `crypten.save_from_party()` here to save data from a particular source, then we will load using `crypten.load_from_party()` in each example to load on a particular source. The following code will save all data we will use to files, then each example will load its data as necessary.\n",
    "\n",
    "(Note that because we are operating on a single machine, all processes will have access to all of the files we are using. However, this still will work as expected when operating across machines.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function save_all_data at 0x13857e980>: it's not the same object as __main__.save_all_data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     crypten\u001b[38;5;241m.\u001b[39msave_from_party(test_features, filenames[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_features\u001b[39m\u001b[38;5;124m\"\u001b[39m], src\u001b[38;5;241m=\u001b[39mBOB)\n\u001b[1;32m     42\u001b[0m     crypten\u001b[38;5;241m.\u001b[39msave_from_party(test_labels, filenames[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m], src\u001b[38;5;241m=\u001b[39mBOB)\n\u001b[0;32m---> 44\u001b[0m \u001b[43msave_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/garbage/CrypTen/venv/lib/python3.12/site-packages/crypten/mpc/context.py:94\u001b[0m, in \u001b[0;36mrun_multiprocess.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     crypten\u001b[38;5;241m.\u001b[39muninit()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[1;32m     97\u001b[0m     process\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function save_all_data at 0x13857e980>: it's not the same object as __main__.save_all_data"
     ]
    }
   ],
   "source": [
    "from crypten import mpc\n",
    "\n",
    "# Specify file locations to save each piece of data\n",
    "filenames = {\n",
    "    \"features\": \"/tmp/features.pth\",\n",
    "    \"labels\": \"/tmp/labels.pth\",\n",
    "    \"features_alice\": \"/tmp/features_alice.pth\",\n",
    "    \"features_bob\": \"/tmp/features_bob.pth\",\n",
    "    \"samples_alice\": \"/tmp/samples_alice.pth\",\n",
    "    \"samples_bob\": \"/tmp/samples_bob.pth\",\n",
    "    \"w_true\": \"/tmp/w_true.pth\",\n",
    "    \"b_true\": \"/tmp/b_true.pth\",\n",
    "    \"test_features\": \"/tmp/test_features.pth\",\n",
    "    \"test_labels\": \"/tmp/test_labels.pth\",\n",
    "}\n",
    "\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def save_all_data():\n",
    "    # Save features, labels for Data Labeling example\n",
    "    crypten.save(features, filenames[\"features\"])\n",
    "    crypten.save(labels, filenames[\"labels\"])\n",
    "    \n",
    "    # Save split features for Feature Aggregation example\n",
    "    features_alice = features[:50]\n",
    "    features_bob = features[50:]\n",
    "    \n",
    "    crypten.save_from_party(features_alice, filenames[\"features_alice\"], src=ALICE)\n",
    "    crypten.save_from_party(features_bob, filenames[\"features_bob\"], src=BOB)\n",
    "    \n",
    "    # Save split dataset for Dataset Aggregation example\n",
    "    samples_alice = features[:, :500]\n",
    "    samples_bob = features[:, 500:]\n",
    "    crypten.save_from_party(samples_alice, filenames[\"samples_alice\"], src=ALICE)\n",
    "    crypten.save_from_party(samples_bob, filenames[\"samples_bob\"], src=BOB)\n",
    "    \n",
    "    # Save true model weights and biases for Model Hiding example\n",
    "    crypten.save_from_party(w_true, filenames[\"w_true\"], src=ALICE)\n",
    "    crypten.save_from_party(b_true, filenames[\"b_true\"], src=ALICE)\n",
    "    \n",
    "    crypten.save_from_party(test_features, filenames[\"test_features\"], src=BOB)\n",
    "    crypten.save_from_party(test_labels, filenames[\"test_labels\"], src=BOB)\n",
    "    \n",
    "save_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: Data Labeling\n",
    "\n",
    "Our first example will focus on the <i>Data Labeling</i> scenario. In this example, Alice has access to features, while Bob has access to the labels. We will train our linear svm by encrypting the features from Alice and the labels from Bob, then training our SVM using an aggregation of the encrypted data.\n",
    "\n",
    "In order to indicate the source of a given encrypted tensor, we encrypt our tensor using `crypten.load()` (from a file) or `crypten.cryptensor()` (from a tensor) using a keyword argument `src`. This `src` argument takes the rank of the party we want to encrypt from (recall that ALICE is 0 and BOB is 1). \n",
    "\n",
    "(If the `src` is not specified, it will default to the rank 0 party. We will use the default when encrypting public values since the source is irrelevant in this case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 --- Training Accuracy 53.40%\n",
      "Epoch 1 --- Training Accuracy 58.70%\n",
      "Epoch 2 --- Training Accuracy 63.80%\n",
      "Epoch 3 --- Training Accuracy 68.30%\n",
      "Epoch 4 --- Training Accuracy 73.60%\n",
      "Epoch 5 --- Training Accuracy 78.00%\n",
      "Epoch 6 --- Training Accuracy 81.00%\n",
      "Epoch 7 --- Training Accuracy 84.60%\n",
      "Epoch 8 --- Training Accuracy 87.00%\n",
      "Epoch 9 --- Training Accuracy 90.40%\n",
      "Epoch 10 --- Training Accuracy 91.50%\n",
      "Epoch 11 --- Training Accuracy 92.90%\n",
      "Epoch 12 --- Training Accuracy 93.80%\n",
      "Epoch 13 --- Training Accuracy 94.30%\n",
      "Epoch 14 --- Training Accuracy 95.50%\n",
      "Epoch 15 --- Training Accuracy 95.80%\n",
      "Epoch 16 --- Training Accuracy 96.30%\n",
      "Epoch 17 --- Training Accuracy 96.60%\n",
      "Epoch 18 --- Training Accuracy 96.70%\n",
      "Epoch 19 --- Training Accuracy 97.40%\n",
      "Epoch 20 --- Training Accuracy 98.30%\n",
      "Epoch 21 --- Training Accuracy 98.00%\n",
      "Epoch 22 --- Training Accuracy 98.10%\n",
      "Epoch 23 --- Training Accuracy 98.00%\n",
      "Epoch 24 --- Training Accuracy 98.70%\n",
      "Epoch 25 --- Training Accuracy 98.70%\n",
      "Epoch 26 --- Training Accuracy 99.30%\n",
      "Epoch 27 --- Training Accuracy 99.70%\n",
      "Epoch 28 --- Training Accuracy 99.60%\n",
      "Epoch 29 --- Training Accuracy 99.50%\n",
      "Epoch 30 --- Training Accuracy 99.70%\n",
      "Epoch 31 --- Training Accuracy 99.50%\n",
      "Epoch 32 --- Training Accuracy 99.60%\n",
      "Epoch 33 --- Training Accuracy 99.80%\n",
      "Epoch 34 --- Training Accuracy 100.00%\n",
      "Epoch 35 --- Training Accuracy 100.00%\n",
      "Epoch 36 --- Training Accuracy 100.00%\n",
      "Epoch 37 --- Training Accuracy 100.00%\n",
      "Epoch 38 --- Training Accuracy 100.00%\n",
      "Epoch 39 --- Training Accuracy 100.00%\n",
      "Test accuracy 92.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crypten import mpc\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def data_labeling_example():\n",
    "    \"\"\"Apply data labeling access control model\"\"\"\n",
    "    # Alice loads features, Bob loads labels\n",
    "    features_enc = crypten.load_from_party(filenames[\"features\"], src=ALICE)\n",
    "    labels_enc = crypten.load_from_party(filenames[\"labels\"], src=BOB)\n",
    "    \n",
    "    # Execute training\n",
    "    w, b = train_linear_svm(features_enc, labels_enc, epochs=epochs, lr=lr)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
    "        \n",
    "data_labeling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: Feature Aggregation\n",
    "\n",
    "Next, we'll show how we can use CrypTen in the <i>Feature Aggregation</i> scenario. Here Alice and Bob each have 50 features for each sample, and would like to use their combined features to train a model. As before, Alice and Bob wish to keep their respective data private. This scenario can occur when multiple parties measure different features of a similar system, and their measurements may be proprietary or otherwise sensitive.\n",
    "\n",
    "Unlike the last scenario, one of our variables is split among two parties. This means we will have to concatenate the tensors encrypted from each party before passing them to the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 --- Training Accuracy 53.40%\n",
      "Epoch 1 --- Training Accuracy 58.70%\n",
      "Epoch 2 --- Training Accuracy 63.80%\n",
      "Epoch 3 --- Training Accuracy 68.30%\n",
      "Epoch 4 --- Training Accuracy 73.60%\n",
      "Epoch 5 --- Training Accuracy 78.00%\n",
      "Epoch 6 --- Training Accuracy 81.00%\n",
      "Epoch 7 --- Training Accuracy 84.60%\n",
      "Epoch 8 --- Training Accuracy 87.00%\n",
      "Epoch 9 --- Training Accuracy 90.40%\n",
      "Epoch 10 --- Training Accuracy 91.50%\n",
      "Epoch 11 --- Training Accuracy 92.90%\n",
      "Epoch 12 --- Training Accuracy 93.80%\n",
      "Epoch 13 --- Training Accuracy 94.40%\n",
      "Epoch 14 --- Training Accuracy 95.30%\n",
      "Epoch 15 --- Training Accuracy 96.30%\n",
      "Epoch 16 --- Training Accuracy 96.20%\n",
      "Epoch 17 --- Training Accuracy 96.80%\n",
      "Epoch 18 --- Training Accuracy 96.80%\n",
      "Epoch 19 --- Training Accuracy 97.20%\n",
      "Epoch 20 --- Training Accuracy 97.90%\n",
      "Epoch 21 --- Training Accuracy 97.80%\n",
      "Epoch 22 --- Training Accuracy 98.00%\n",
      "Epoch 23 --- Training Accuracy 98.90%\n",
      "Epoch 24 --- Training Accuracy 99.20%\n",
      "Epoch 25 --- Training Accuracy 99.40%\n",
      "Epoch 26 --- Training Accuracy 99.30%\n",
      "Epoch 27 --- Training Accuracy 99.50%\n",
      "Epoch 28 --- Training Accuracy 99.30%\n",
      "Epoch 29 --- Training Accuracy 99.30%\n",
      "Epoch 30 --- Training Accuracy 99.30%\n",
      "Epoch 31 --- Training Accuracy 99.50%\n",
      "Epoch 32 --- Training Accuracy 99.60%\n",
      "Epoch 33 --- Training Accuracy 100.00%\n",
      "Epoch 34 --- Training Accuracy 100.00%\n",
      "Epoch 35 --- Training Accuracy 100.00%\n",
      "Epoch 36 --- Training Accuracy 100.00%\n",
      "Epoch 37 --- Training Accuracy 100.00%\n",
      "Epoch 38 --- Training Accuracy 100.00%\n",
      "Epoch 39 --- Training Accuracy 100.00%\n",
      "Test accuracy 92.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def feature_aggregation_example():\n",
    "    \"\"\"Apply feature aggregation access control model\"\"\"\n",
    "    # Alice loads some features, Bob loads other features\n",
    "    features_alice_enc = crypten.load_from_party(filenames[\"features_alice\"], src=ALICE)\n",
    "    features_bob_enc = crypten.load_from_party(filenames[\"features_bob\"], src=BOB)\n",
    "    \n",
    "    # Concatenate features\n",
    "    features_enc = crypten.cat([features_alice_enc, features_bob_enc], dim=0)\n",
    "    \n",
    "    # Encrypt labels\n",
    "    labels_enc = crypten.cryptensor(labels)\n",
    "    \n",
    "    # Execute training\n",
    "    w, b = train_linear_svm(features_enc, labels_enc, epochs=epochs, lr=lr)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
    "        \n",
    "feature_aggregation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Dataset Augmentation\n",
    "\n",
    "The next example shows how we can use CrypTen in a <i>Data Augmentation</i> scenario. Here Alice and Bob each have 500 samples, and would like to learn a classifier over their combined sample data. This scenario can occur in applications where several parties may each have access to a small amount of sensitive data, where no individual party has enough data to train an accurate model.\n",
    "\n",
    "Like the last scenario, one of our variables is split amongst parties, so we will have to concatenate tensors from encrypted from different parties. The main difference from the last scenario is that we are concatenating over the other dimension (the sample dimension rather than the feature dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 --- Training Accuracy 53.40%\n",
      "Epoch 1 --- Training Accuracy 58.70%\n",
      "Epoch 2 --- Training Accuracy 63.80%\n",
      "Epoch 3 --- Training Accuracy 68.30%\n",
      "Epoch 4 --- Training Accuracy 73.60%\n",
      "Epoch 5 --- Training Accuracy 78.00%\n",
      "Epoch 6 --- Training Accuracy 81.00%\n",
      "Epoch 7 --- Training Accuracy 84.60%\n",
      "Epoch 8 --- Training Accuracy 87.00%\n",
      "Epoch 9 --- Training Accuracy 90.40%\n",
      "Epoch 10 --- Training Accuracy 91.50%\n",
      "Epoch 11 --- Training Accuracy 92.90%\n",
      "Epoch 12 --- Training Accuracy 93.80%\n",
      "Epoch 13 --- Training Accuracy 94.40%\n",
      "Epoch 14 --- Training Accuracy 95.30%\n",
      "Epoch 15 --- Training Accuracy 96.30%\n",
      "Epoch 16 --- Training Accuracy 96.20%\n",
      "Epoch 17 --- Training Accuracy 96.80%\n",
      "Epoch 18 --- Training Accuracy 96.80%\n",
      "Epoch 19 --- Training Accuracy 97.20%\n",
      "Epoch 20 --- Training Accuracy 97.90%\n",
      "Epoch 21 --- Training Accuracy 97.80%\n",
      "Epoch 22 --- Training Accuracy 98.00%\n",
      "Epoch 23 --- Training Accuracy 98.90%\n",
      "Epoch 24 --- Training Accuracy 99.20%\n",
      "Epoch 25 --- Training Accuracy 99.40%\n",
      "Epoch 26 --- Training Accuracy 99.50%\n",
      "Epoch 27 --- Training Accuracy 99.50%\n",
      "Epoch 28 --- Training Accuracy 99.00%\n",
      "Epoch 29 --- Training Accuracy 99.30%\n",
      "Epoch 30 --- Training Accuracy 99.30%\n",
      "Epoch 31 --- Training Accuracy 99.40%\n",
      "Epoch 32 --- Training Accuracy 99.50%\n",
      "Epoch 33 --- Training Accuracy 99.90%\n",
      "Epoch 34 --- Training Accuracy 99.80%\n",
      "Epoch 35 --- Training Accuracy 99.90%\n",
      "Epoch 36 --- Training Accuracy 99.90%\n",
      "Epoch 37 --- Training Accuracy 99.80%\n",
      "Epoch 38 --- Training Accuracy 99.90%\n",
      "Epoch 39 --- Training Accuracy 99.90%\n",
      "Test accuracy 92.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def dataset_augmentation_example():\n",
    "    \"\"\"Apply dataset augmentation access control model\"\"\" \n",
    "    # Alice loads some samples, Bob loads other samples\n",
    "    samples_alice_enc = crypten.load_from_party(filenames[\"samples_alice\"], src=ALICE)\n",
    "    samples_bob_enc = crypten.load_from_party(filenames[\"samples_bob\"], src=BOB)\n",
    "    \n",
    "    # Concatenate features\n",
    "    samples_enc = crypten.cat([samples_alice_enc, samples_bob_enc], dim=1)\n",
    "    \n",
    "    labels_enc = crypten.cryptensor(labels)\n",
    "    \n",
    "    # Execute training\n",
    "    w, b = train_linear_svm(samples_enc, labels_enc, epochs=epochs, lr=lr)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_linear_svm(test_features, test_labels, w, b)\n",
    "        \n",
    "dataset_augmentation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: Model Hiding\n",
    "\n",
    "The last scenario we will explore involves <i>model hiding</i>. Here, Alice has a pre-trained model that cannot be revealed, while Bob would like to use this model to evaluate on private data sample(s). This scenario can occur when a pre-trained model is proprietary or contains sensitive information, but can provide value to other parties with sensitive data.\n",
    "\n",
    "This scenario is somewhat different from the previous examples because we are not interested in training the model. Therefore, we do not need labels. Instead, we will demonstrate this example by encrypting the true model parameters (`w_true` and `b_true`) from Alice and encrypting the test set from Bob for evaluation.\n",
    "\n",
    "(Note: Because we are using the true weights and biases used to generate the test labels, we will get 100% accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def model_hiding_example():\n",
    "    \"\"\"Apply model hiding access control model\"\"\"\n",
    "    # Alice loads the model\n",
    "    w_true_enc = crypten.load_from_party(filenames[\"w_true\"], src=ALICE)\n",
    "    b_true_enc = crypten.load_from_party(filenames[\"b_true\"], src=ALICE)\n",
    "    \n",
    "    # Bob loads the features to be evaluated\n",
    "    test_features_enc = crypten.load_from_party(filenames[\"test_features\"], src=BOB)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_linear_svm(test_features_enc, test_labels, w_true_enc, b_true_enc)\n",
    "    \n",
    "model_hiding_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we have reviewed four techniques where CrypTen can be used to perform encrypted training / inference. Each of these techniques can be used to facilitate computations in different privacy-preserving scenarios. However, these techniques can also be combined to increase the amount of scenarios where CrypTen can maintain privacy.\n",
    "\n",
    "For example, we can combine feature aggregation and data labeling to train a model on data split between three parties, where two parties each have access to a subset of features, and the third party has access to labels.\n",
    "\n",
    "Before exiting this tutorial, please clean up the files generated using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for fn in filenames.values():\n",
    "    if os.path.exists(fn): os.remove(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
